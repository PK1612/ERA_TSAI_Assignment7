{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-20T20:30:32.036849Z","iopub.status.busy":"2024-12-20T20:30:32.036613Z","iopub.status.idle":"2024-12-20T20:30:35.924055Z","shell.execute_reply":"2024-12-20T20:30:35.923393Z","shell.execute_reply.started":"2024-12-20T20:30:32.036822Z"},"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torchvision import datasets, transforms\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["# Model 2"]},{"cell_type":"markdown","metadata":{},"source":["**Target:**\n","\n","Not changing this skeleton as much as possible, if we can reach the desired accuracy with this. Since the model is underfitting, we can try using some rotation to help it train better. We can add other augmentations 1 by 1, so as to see if there is any impact. \n","\n","Results:\n","1. Parameters: **7.9k**\n","2. Best Train Accuracy: **98.71%**\n","3. Best Test Accuracy: **99.35%**\n","\n","Analysis:\n","1. The model is still under-fitting and we can see that there is more scope for training and improving the accruacy.\n","2. Although we are not hitting the desired accuracy in test or train, we do see that the model does stabilise at test accuracy ~ 99.3%\n","3. We can play with the learning rate to improve the training accuracy or the learning a bit more. "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:30:49.125021Z","iopub.status.busy":"2024-12-20T20:30:49.124682Z","iopub.status.idle":"2024-12-20T20:30:49.130202Z","shell.execute_reply":"2024-12-20T20:30:49.129282Z","shell.execute_reply.started":"2024-12-20T20:30:49.124991Z"},"trusted":true},"outputs":[],"source":["# Train Phase transformations\n","train_transforms = transforms.Compose([\n","                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,))\n","                                       ])\n","\n","# Test Phase transformations\n","test_transforms = transforms.Compose([\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,))\n","                                       ])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:30:51.886009Z","iopub.status.busy":"2024-12-20T20:30:51.885160Z","iopub.status.idle":"2024-12-20T20:30:54.537816Z","shell.execute_reply":"2024-12-20T20:30:54.536947Z","shell.execute_reply.started":"2024-12-20T20:30:51.885944Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 41253971.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 1120319.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 10439364.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 3571527.70it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:30:59.291008Z","iopub.status.busy":"2024-12-20T20:30:59.290674Z","iopub.status.idle":"2024-12-20T20:30:59.379343Z","shell.execute_reply":"2024-12-20T20:30:59.378308Z","shell.execute_reply.started":"2024-12-20T20:30:59.290948Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA Available? True\n"]}],"source":["SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n","dataloader_args = dict(shuffle=True, batch_size=32, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","\n","# train dataloader\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n","\n","# test dataloader\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:31:07.230678Z","iopub.status.busy":"2024-12-20T20:31:07.229872Z","iopub.status.idle":"2024-12-20T20:31:07.240460Z","shell.execute_reply":"2024-12-20T20:31:07.239572Z","shell.execute_reply.started":"2024-12-20T20:31:07.230647Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","  model.train()\n","  pbar = tqdm(train_loader)\n","  correct = 0\n","  processed = 0\n","  for batch_idx, (data, target) in enumerate(pbar):\n","    # get samples\n","    data, target = data.to(device), target.to(device)\n","\n","    # Init\n","    optimizer.zero_grad()\n","    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n","    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","\n","    # Predict\n","    y_pred = model(data)\n","\n","    # Calculate loss\n","    loss = F.nll_loss(y_pred, target)\n","    train_losses.append(loss)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Update pbar-tqdm\n","    \n","    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    correct += pred.eq(target.view_as(pred)).sum().item()\n","    processed += len(data)\n","\n","    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n","    train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_losses.append(test_loss)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_loader.dataset))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:31:11.727574Z","iopub.status.busy":"2024-12-20T20:31:11.727179Z","iopub.status.idle":"2024-12-20T20:31:11.738493Z","shell.execute_reply":"2024-12-20T20:31:11.737610Z","shell.execute_reply.started":"2024-12-20T20:31:11.727548Z"},"trusted":true},"outputs":[],"source":["dropout_value = 0.1\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(10),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=12, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(12),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 24\n","\n","        # TRANSITION BLOCK 1\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","        ) # output_size = 24\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(10),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 10\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 8\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=12, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),            \n","            nn.BatchNorm2d(12),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6\n","        \n","        # OUTPUT BLOCK\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=6)\n","        ) # output_size = 1\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=12, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)#,\n","            # nn.BatchNorm2d(10),\n","            # nn.ReLU(),\n","            # nn.Dropout(dropout_value)\n","        ) \n","\n","\n","        self.dropout = nn.Dropout(dropout_value)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.gap(x)        \n","        x = self.convblock8(x)\n","\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:31:16.606305Z","iopub.status.busy":"2024-12-20T20:31:16.605351Z","iopub.status.idle":"2024-12-20T20:31:26.750001Z","shell.execute_reply":"2024-12-20T20:31:26.748993Z","shell.execute_reply.started":"2024-12-20T20:31:16.606254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchsummary\n","  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n","Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n","Installing collected packages: torchsummary\n","Successfully installed torchsummary-1.5.1\n","cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 26, 26]              90\n","              ReLU-2           [-1, 10, 26, 26]               0\n","       BatchNorm2d-3           [-1, 10, 26, 26]              20\n","           Dropout-4           [-1, 10, 26, 26]               0\n","            Conv2d-5           [-1, 12, 24, 24]           1,080\n","              ReLU-6           [-1, 12, 24, 24]               0\n","       BatchNorm2d-7           [-1, 12, 24, 24]              24\n","           Dropout-8           [-1, 12, 24, 24]               0\n","            Conv2d-9           [-1, 10, 24, 24]             120\n","        MaxPool2d-10           [-1, 10, 12, 12]               0\n","           Conv2d-11           [-1, 10, 10, 10]             900\n","             ReLU-12           [-1, 10, 10, 10]               0\n","      BatchNorm2d-13           [-1, 10, 10, 10]              20\n","          Dropout-14           [-1, 10, 10, 10]               0\n","           Conv2d-15             [-1, 16, 8, 8]           1,440\n","             ReLU-16             [-1, 16, 8, 8]               0\n","      BatchNorm2d-17             [-1, 16, 8, 8]              32\n","          Dropout-18             [-1, 16, 8, 8]               0\n","           Conv2d-19             [-1, 16, 6, 6]           2,304\n","             ReLU-20             [-1, 16, 6, 6]               0\n","      BatchNorm2d-21             [-1, 16, 6, 6]              32\n","          Dropout-22             [-1, 16, 6, 6]               0\n","           Conv2d-23             [-1, 12, 6, 6]           1,728\n","             ReLU-24             [-1, 12, 6, 6]               0\n","      BatchNorm2d-25             [-1, 12, 6, 6]              24\n","          Dropout-26             [-1, 12, 6, 6]               0\n","        AvgPool2d-27             [-1, 12, 1, 1]               0\n","           Conv2d-28             [-1, 10, 1, 1]             120\n","================================================================\n","Total params: 7,934\n","Trainable params: 7,934\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.56\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.60\n","----------------------------------------------------------------\n"]}],"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-20T20:31:35.864432Z","iopub.status.busy":"2024-12-20T20:31:35.863566Z","iopub.status.idle":"2024-12-20T20:35:52.660054Z","shell.execute_reply":"2024-12-20T20:35:52.658930Z","shell.execute_reply.started":"2024-12-20T20:31:35.864395Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH: 0\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.1367136538028717 Batch_id=1874 Accuracy=92.60: 100%|██████████| 1875/1875 [00:15<00:00, 119.18it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0643, Accuracy: 9796/10000 (97.96%)\n","\n","EPOCH: 1\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.034736983478069305 Batch_id=1874 Accuracy=97.33: 100%|██████████| 1875/1875 [00:15<00:00, 120.36it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0396, Accuracy: 9853/10000 (98.53%)\n","\n","EPOCH: 2\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.20239630341529846 Batch_id=1874 Accuracy=97.78: 100%|██████████| 1875/1875 [00:15<00:00, 120.83it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0388, Accuracy: 9878/10000 (98.78%)\n","\n","EPOCH: 3\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.04738576337695122 Batch_id=1874 Accuracy=97.98: 100%|██████████| 1875/1875 [00:15<00:00, 117.81it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0359, Accuracy: 9881/10000 (98.81%)\n","\n","EPOCH: 4\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.028591865673661232 Batch_id=1874 Accuracy=98.05: 100%|██████████| 1875/1875 [00:15<00:00, 119.95it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0314, Accuracy: 9902/10000 (99.02%)\n","\n","EPOCH: 5\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.007116924040019512 Batch_id=1874 Accuracy=98.50: 100%|██████████| 1875/1875 [00:15<00:00, 119.48it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0245, Accuracy: 9919/10000 (99.19%)\n","\n","EPOCH: 6\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.08840946108102798 Batch_id=1874 Accuracy=98.59: 100%|██████████| 1875/1875 [00:15<00:00, 122.36it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0222, Accuracy: 9935/10000 (99.35%)\n","\n","EPOCH: 7\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.026110341772437096 Batch_id=1874 Accuracy=98.67: 100%|██████████| 1875/1875 [00:15<00:00, 119.45it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0239, Accuracy: 9928/10000 (99.28%)\n","\n","EPOCH: 8\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.003310647327452898 Batch_id=1874 Accuracy=98.70: 100%|██████████| 1875/1875 [00:15<00:00, 119.11it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0225, Accuracy: 9926/10000 (99.26%)\n","\n","EPOCH: 9\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.07820355892181396 Batch_id=1874 Accuracy=98.60: 100%|██████████| 1875/1875 [00:15<00:00, 120.81it/s]   \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0216, Accuracy: 9931/10000 (99.31%)\n","\n","EPOCH: 10\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.014352616854012012 Batch_id=1874 Accuracy=98.67: 100%|██████████| 1875/1875 [00:15<00:00, 119.78it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0214, Accuracy: 9932/10000 (99.32%)\n","\n","EPOCH: 11\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.041270796209573746 Batch_id=1874 Accuracy=98.69: 100%|██████████| 1875/1875 [00:15<00:00, 122.05it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0212, Accuracy: 9932/10000 (99.32%)\n","\n","EPOCH: 12\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.003971356898546219 Batch_id=1874 Accuracy=98.67: 100%|██████████| 1875/1875 [00:15<00:00, 119.77it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0221, Accuracy: 9932/10000 (99.32%)\n","\n","EPOCH: 13\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.27241086959838867 Batch_id=1874 Accuracy=98.71: 100%|██████████| 1875/1875 [00:15<00:00, 122.12it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0216, Accuracy: 9930/10000 (99.30%)\n","\n","EPOCH: 14\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.013252783566713333 Batch_id=1874 Accuracy=98.69: 100%|██████████| 1875/1875 [00:15<00:00, 118.52it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0224, Accuracy: 9932/10000 (99.32%)\n","\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","\n","model =  Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","\n","EPOCHS = 15\n","for epoch in range(EPOCHS):\n","    print(\"EPOCH:\", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    scheduler.step()\n","    test(model, device, test_loader)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30804,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
